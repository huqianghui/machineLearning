K-平均算法（英文：k-means clustering）

源于信号处理中的一种向量量化方法，现在则更多地作为一种聚类分析方法流行于数据挖掘领域。
k-平均聚类的目的是：把 个点（可以是样本的一次观察或一个实例）划分到k个聚类中，使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。这个问题将归结为一个把数据空间划分为Voronoi cells的问题。

这个问题在计算上是NP困难的，不过存在高效的启发式算法。
一般情况下，都使用效率比较高的启发式算法，它们能够快速收敛于一个局部最优解。
这些算法通常类似于通过迭代优化方法处理高斯混合分布的最大期望算法（EM算法）。
而且，它们都使用聚类中心来为数据建模；然而k-平均聚类倾向于在可比较的空间范围内寻找聚类，期望-最大化技术却允许聚类有不同的形状。


复杂度
在{\displaystyle d}d维空间中找到k-均值聚类问题的最优解的计算复杂度：

NP-hard：一般欧式空间中，即使目标聚类数仅为2[12][13]
NP困难：平面中，不对聚类数目k作限制[14]
如果k和{\displaystyle d}d都是固定的，时间复杂度为{\displaystyle O(n^{dk+1}logn)}O(n^{{dk+1}}logn),其中{\displaystyle n}n为待聚类的观测点数目[15]
相比之下，Lloyds算法的运行时间通常为{\displaystyle O(nkdi)}O(nkdi),k和{\displaystyle d}d定义如上，{\displaystyle i}i为直到收敛时的迭代次数。如果数据本身就有一定的聚类结构，那么收敛所需的迭代数目通常是很少的，并且进行少数迭代之后，再进行迭代的话，对于结果的改善效果很小。鉴于上述原因，Lloyds算法在实践中通常被认为几乎是线性复杂度的。

下面有几个关于这一算法复杂度的近期研究：

Lloyd's k-均值算法具有多项式平滑运行时间。对于落在空间{\displaystyle [0,1]^{d}}[0,1]^{d}任意的{\displaystyle n}n点集合，如果每一个点都独立地受一个均值为{\displaystyle 0}{\displaystyle 0}，标准差为{\displaystyle \sigma }\sigma 的正态分布所影响，那么k-均值算法的期望运行时间上界为{\displaystyle O(n^{34}k^{34}d^{8}log^{4}(n)/\sigma ^{6})}O(n^{{34}}k^{{34}}d^{{8}}log^{4}(n)/\sigma ^{6})，即对于{\displaystyle n,k,i,d}n,k,i,d和{\displaystyle 1/\sigma }1/\sigma 都是多项式时间的[11]。
在更简单的情况下，有更好的上界。例如[16]，在整数网格{\displaystyle \left\{1,...,M\right\}^{d}}\left\{1,...,M\right\}^{d}中，k-均值算法运行时间的上界为{\displaystyle O(dn^{4}M^{2})}O(dn^{4}M^{2})。