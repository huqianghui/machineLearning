{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import logging\n",
    "\n",
    "def jiebaProcess():\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "    jieba.load_userdict(\"userDict.txt\")\n",
    "    # load stopwords set\n",
    "    stopword_set = set()\n",
    "    with open('stopwords.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.add(stopword.strip('\\n'))\n",
    "\n",
    "    output = open('san_seg.txt', 'w', encoding='utf-8')\n",
    "    with open('san.txt', 'r', encoding='utf-8') as content :\n",
    "        for texts_num, line in enumerate(content):\n",
    "            line = line.strip('\\n')\n",
    "            words = jieba.cut(line, cut_all=False)\n",
    "            for word in words:\n",
    "                if word not in stopword_set:\n",
    "                    output.write(word + ' ')\n",
    "            output.write('\\n')\n",
    "\n",
    "            if (texts_num + 1) % 10000 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % (texts_num + 1))\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiebaProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-26 18:18:19,312 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-03-26 18:18:19,315 : INFO : collecting all words and their counts\n",
      "2020-03-26 18:18:19,318 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-03-26 18:18:19,496 : INFO : collected 64381 word types from a corpus of 345185 raw words and 8105 sentences\n",
      "2020-03-26 18:18:19,497 : INFO : Loading a fresh vocabulary\n",
      "2020-03-26 18:18:19,548 : INFO : effective_min_count=5 retains 10464 unique words (16% of original 64381, drops 53917)\n",
      "2020-03-26 18:18:19,549 : INFO : effective_min_count=5 leaves 263247 word corpus (76% of original 345185, drops 81938)\n",
      "2020-03-26 18:18:19,586 : INFO : deleting the raw counts dictionary of 64381 items\n",
      "2020-03-26 18:18:19,588 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2020-03-26 18:18:19,589 : INFO : downsampling leaves estimated 232816 word corpus (88.4% of prior 263247)\n",
      "2020-03-26 18:18:19,610 : INFO : estimated required memory for 10464 words and 250 dimensions: 26160000 bytes\n",
      "2020-03-26 18:18:19,611 : INFO : resetting layer weights\n",
      "2020-03-26 18:18:22,167 : INFO : training model with 3 workers on 10464 vocabulary and 250 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-03-26 18:18:22,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-26 18:18:22,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-26 18:18:22,479 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-26 18:18:22,480 : INFO : EPOCH - 1 : training on 345185 raw words (232858 effective words) took 0.3s, 751476 effective words/s\n",
      "2020-03-26 18:18:22,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-26 18:18:22,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-26 18:18:22,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-26 18:18:22,815 : INFO : EPOCH - 2 : training on 345185 raw words (232775 effective words) took 0.3s, 700469 effective words/s\n",
      "2020-03-26 18:18:23,108 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-26 18:18:23,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-26 18:18:23,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-26 18:18:23,126 : INFO : EPOCH - 3 : training on 345185 raw words (232819 effective words) took 0.3s, 755610 effective words/s\n",
      "2020-03-26 18:18:23,448 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-26 18:18:23,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-26 18:18:23,455 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-26 18:18:23,455 : INFO : EPOCH - 4 : training on 345185 raw words (232780 effective words) took 0.3s, 711224 effective words/s\n",
      "2020-03-26 18:18:23,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-26 18:18:23,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-26 18:18:23,741 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-26 18:18:23,741 : INFO : EPOCH - 5 : training on 345185 raw words (232653 effective words) took 0.3s, 819343 effective words/s\n",
      "2020-03-26 18:18:23,742 : INFO : training on a 1725925 raw words (1163885 effective words) took 1.6s, 739739 effective words/s\n",
      "2020-03-26 18:18:23,742 : INFO : saving Word2Vec object under word2vec.model, separately None\n",
      "2020-03-26 18:18:23,743 : INFO : not storing attribute vectors_norm\n",
      "2020-03-26 18:18:23,743 : INFO : not storing attribute cum_table\n",
      "2020-03-26 18:18:23,966 : INFO : saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def train():\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    sentences = word2vec.LineSentence(\"san_seg.txt\")\n",
    "    model = word2vec.Word2Vec(sentences, size=250)\n",
    "\n",
    "    #保存模型，供日後使用\n",
    "    model.save(\"word2vec.model\")\n",
    "\n",
    "    #模型讀取方式\n",
    "    # model = word2vec.Word2Vec.load(\"your_model_name\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "import logging\n",
    "\n",
    "def demo():\n",
    "\tlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\tmodel = models.Word2Vec.load('word2vec.model')\n",
    "\n",
    "\tprint(\"提供3种测试模式\\n\")\n",
    "\tprint(\"输入一个词，则去寻找前10个相似的词\")\n",
    "\tprint(\"输入两个词，计算两个词的相似度\")\n",
    "\tprint(\"输入三个词，则进行词类推\")\n",
    "\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tquery = input()\n",
    "\t\t\tq_list = query.split()\n",
    "\n",
    "\t\t\tif len(q_list) == 1:\n",
    "\t\t\t\tprint(\"相似词 10 排序\")\n",
    "\t\t\t\tres = model.most_similar(q_list[0],topn = 10)\n",
    "\t\t\t\tfor item in res:\n",
    "\t\t\t\t\tprint(item[0]+\",\"+str(item[1]))\n",
    "\n",
    "\t\t\telif len(q_list) == 2:\n",
    "\t\t\t\tprint(\"计算 Cosine 相似度\")\n",
    "\t\t\t\tres = model.similarity(q_list[0],q_list[1])\n",
    "\t\t\t\tprint(res)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"%s之于%s，如%s之于\" % (q_list[0],q_list[2],q_list[1]))\n",
    "\t\t\t\tres = model.most_similar([q_list[0],q_list[1]], [q_list[2]], topn= 10)\n",
    "\t\t\t\tfor item in res:\n",
    "\t\t\t\t\tprint(item[0]+\",\"+str(item[1]))\n",
    "\t\t\tprint(\"----------------------------\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-26 18:18:23,996 : INFO : loading Word2Vec object from word2vec.model\n",
      "2020-03-26 18:18:24,180 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "2020-03-26 18:18:24,181 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-03-26 18:18:24,182 : INFO : loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "2020-03-26 18:18:24,182 : INFO : loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "2020-03-26 18:18:24,183 : INFO : setting ignored attribute cum_table to None\n",
      "2020-03-26 18:18:24,183 : INFO : loaded word2vec.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提供3种测试模式\n",
      "\n",
      "输入一个词，则去寻找前10个相似的词\n",
      "输入两个词，计算两个词的相似度\n",
      "输入三个词，则进行词类推\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 刘备 的卢\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huqianghui/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算 Cosine 相似度\n",
      "KeyError(\"word '的卢' not in vocabulary\")\n"
     ]
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
